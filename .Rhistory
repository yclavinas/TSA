setwd("~/Documents/SentimentAnalysisTSA")
setwd("~/Documents/SentimentAnalysisTSA")
setwd("~/Documents/SentimentAnalysisTSA/")
setwd("~/Documents/SentimentAnalysis/TSA")
setwd("~/Documents/SentimentAnalysis/TSA")
library(tm)
library(wordcloud)
library(tm)
library(tm)
install.packages("tm")
library(tm)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,tolower)
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
#Definetdmcomoumamatriz
m=as.matrix(tdm)
#Recuperaafrequenciadaspalavrasemordemdecrescente
palavras_freq=sort(rowSums(m),decreasing=TRUE) #Filtraparaficarapenascomaspalavrasmaisfrequentes
lim=quantile(palavras_freq,probs=0.25)
palavras_freq_top=palavras_freq[palavras_freq>lim]
palavras_freq_top=palavras_freq_top[c(-1, -2, -3)]
dm=data.frame(word=names(palavras_freq_top),freq=palavras_freq_top)
#Removeapalavramaisfrequente
wordcloud(dm$word,dm$freq,random.order= T, random.color = F,, colors=brewer.pal(8,"Dark2"), max.words = 150, min.freq = 0.1)
head(palavras_freq_top, n = 150)
palavras_freq_top[142]
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,tolower)
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
corpus=tm_map(corpus,removeNumbers)
tdm=TermDocumentMatrix(corpus)
palavras_freq=sort(rowSums(m),decreasing=TRUE) #Filtraparaficarapenascomaspalavrasmaisfrequentes
setwd("~/Documents")
setwd("~/Documents/SentimentAnalysis")
library(tm)
library(wordcloud)
library(RColorBrewer)
library(Snowball)
text = read.csv2("twitDB_CPBR_NoUrl_2014.txt", header = F)
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,tolower)
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("portuguese"))
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
#Definetdmcomoumamatriz
m=as.matrix(tdm)
text = read.csv2("twitDB_CPBR_NoUrl_2014.txt", header = F)
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,tolower)
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("portuguese"))
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
setwd("~/Documents/SentimentAnalysis/TSA")
library(tm)
library(wordcloud)
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,tolower)
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
tdm=TermDocumentMatrix(corpus)
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
tdm=TermDocumentMatrix(corpus)
corpus=tm_map(corpus,content_transformer(tolower))
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
#Definetdmcomoumamatriz
m=as.matrix(tdm)
#Recuperaafrequenciadaspalavrasemordemdecrescente
palavras_freq=sort(rowSums(m),decreasing=TRUE) #Filtraparaficarapenascomaspalavrasmaisfrequentes
lim=quantile(palavras_freq,probs=0.25)
palavras_freq_top=palavras_freq[palavras_freq>lim]
palavras_freq_top=palavras_freq_top[c(-1, -2, -3)]
dm=data.frame(word=names(palavras_freq_top),freq=palavras_freq_top)
#Removeapalavramaisfrequente
wordcloud(dm$word,dm$freq,random.order= T, random.color = F,, colors=brewer.pal(8,"Dark2"), max.words = 150, min.freq = 0.1)
head(palavras_freq_top, n = 150)
palavras_freq_top[142]
palavras_freq_top
setwd("~/Documents/SentimentAnalysis/TSA")
library(tm)
library(wordcloud)
text <- readLines("TsukubaShi_noUrl.txt", encoding="UTF-8")
corpus=Corpus(VectorSource(text))
corpus=tm_map(corpus,stripWhitespace)
##Convertetudoparaletraminuscula
corpus=tm_map(corpus,content_transformer(tolower))
##Removepontuacao
corpus<-tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords("english"))
corpus=tm_map(corpus,removeNumbers)
#term-documentmatrix
tdm=TermDocumentMatrix(corpus)
#Definetdmcomoumamatriz
m=as.matrix(tdm)
#Recuperaafrequenciadaspalavrasemordemdecrescente
palavras_freq=sort(rowSums(m),decreasing=TRUE) #Filtraparaficarapenascomaspalavrasmaisfrequentes
lim=quantile(palavras_freq,probs=0.25)
palavras_freq_top=palavras_freq[palavras_freq>lim]
dm=data.frame(word=names(palavras_freq_top),freq=palavras_freq_top)
#Removeapalavramaisfrequente
wordcloud(dm$word,dm$freq,random.order= T, random.color = F,, colors=brewer.pal(8,"Dark2"))
palavras_freq_top=palavras_freq_top[c(-1, -2, -3)]
dm=data.frame(word=names(palavras_freq_top),freq=palavras_freq_top)
wordcloud(dm$word,dm$freq,random.order= T, random.color = F,, colors=brewer.pal(8,"Dark2"), max.words = 150, min.freq = 0.1)
wordcloud(dm$word,dm$freq,random.order= T, random.color = F,, colors=brewer.pal(8,"Dark2"))
